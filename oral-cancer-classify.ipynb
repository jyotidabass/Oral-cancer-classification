{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing Necessary Libraries\nimport cv2\nimport os\nimport shutil \nimport math\nimport random\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T07:51:42.507538Z","iopub.execute_input":"2022-06-13T07:51:42.508468Z","iopub.status.idle":"2022-06-13T07:51:43.773361Z","shell.execute_reply.started":"2022-06-13T07:51:42.508341Z","shell.execute_reply":"2022-06-13T07:51:43.772424Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Function to remove Duplicate Images in the Dataset\ndef findDelDuplImg(file_name , file_dir):\n    searchedImgPath = os.path.join(file_dir, file_name);\n    searchedImage = np.array(cv2.imread(searchedImgPath, 0));\n    # Start iterate over all images\n    for cmpImageName in os.listdir(file_dir):\n        if cmpImageName != file_name:\n            # If name is different\n            try:\n                # Concatenate path to image\n                cmpImagePath = os.path.join(file_dir, cmpImageName);\n                # Open image to be compared\n                cmpImage = np.array(cv2.imread(cmpImagePath, 0))\n                # Count root mean square between both images (RMS)\n                rms = math.sqrt(mean_squared_error(searchedImage, cmpImage))\n            except:\n                continue\n            # If RMS is smaller than 3 - this means that images are similar or the same\n            if rms < 3:\n                # Delete Same Image in Dir\n                os.remove(cmpImagePath);\n                \n# Function for Image preprocessing\ndef processDataset(dataset_src, dataset_dest):\n    # Making a Copy of Dataset\n    shutil.copytree(src, dest)\n    for folder in os.listdir(dest):\n        for (index, file) in enumerate(os.listdir(os.path.join(dest, folder)), start = 1):\n            filename = f'img_{folder}_{index}.jpg';\n            img_src = os.path.join(dest, folder, file);\n            img_des = os.path.join(dest, folder, filename);\n            # Preprocess the Images\n            img = cv2.imread(img_src);\n            img = cv2.resize(img, (256, 256));\n            img = cv2.copyMakeBorder(img, 2, 2, 2, 2, cv2.BORDER_CONSTANT, value=0);\n            img = cv2.blur(img, (2, 2));\n            cv2.imwrite(img_des ,img);\n            os.remove(img_src);\n        for file in os.listdir(os.path.join(dest, folder)):\n                # Find duplicated images and delete duplicates.\n                findDelDuplImg(file, os.path.join(dest, folder));\n\n# Source Location for Dataset\nsrc = '../input/oral-cancer-lips-and-tongue-images/OralCancer';\n# Destination Location for Dataset\ndest = './OralCancer';\n# Image preprocessing\nprocessDataset(src, dest);","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:51:48.637349Z","iopub.execute_input":"2022-06-13T07:51:48.637720Z","iopub.status.idle":"2022-06-13T07:52:00.867636Z","shell.execute_reply.started":"2022-06-13T07:51:48.637685Z","shell.execute_reply":"2022-06-13T07:52:00.866569Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def GetDatasetSize(path):\n    num_of_image = {}\n    for folder in os.listdir(path):\n        # Counting the Number of Files in the Folder\n        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n    return num_of_image;\n    \npath = \"./OralCancer\"\nDatasetSize = GetDatasetSize(path);\nprint(DatasetSize);","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:52:06.308196Z","iopub.execute_input":"2022-06-13T07:52:06.308925Z","iopub.status.idle":"2022-06-13T07:52:06.317760Z","shell.execute_reply.started":"2022-06-13T07:52:06.308873Z","shell.execute_reply":"2022-06-13T07:52:06.316795Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"###  Split the Dataset such that we have \n* 70% for Train Data\n* 15% for Validation Data\n* 15% for Testing Data","metadata":{}},{"cell_type":"code","source":"# Function for Creating Train / Validation / Test folders (One time use Only)\n \ndef TrainValTestSplit(root_dir, classes_dir, val_ratio = 0.15, test_ratio = 0.15):\n    for cls in classes_dir:\n        # Creating Split Folders\n        os.makedirs('train/' + cls)\n        os.makedirs('val/' + cls)\n        os.makedirs('test/' + cls)\n\n        # Folder to copy images from\n        src = root_dir + cls\n        \n        # Storing the Filenames\n        allFileNames = os.listdir(src)\n        np.random.shuffle(allFileNames)\n        # Spliting the Files in the Given ratio\n        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames), [int(len(allFileNames)* (1 - (val_ratio + test_ratio))), int(len(allFileNames)* (1 - test_ratio))])\n\n        train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n        val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n        test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n\n        # Printing the Split Details\n        print(cls.upper(),':')\n        print('Total images: ', len(allFileNames))\n        print('Training: ', len(train_FileNames))\n        print('Validation: ', len(val_FileNames))\n        print('Testing: ', len(test_FileNames))\n\n        # Copy-pasting images\n        for name in train_FileNames:\n            shutil.copy(name, 'train/' + cls)\n\n        for name in val_FileNames:\n            shutil.copy(name, 'val/' + cls)\n\n        for name in test_FileNames:\n            shutil.copy(name, 'test/' + cls)\n        print();\n\n# Preforming Train / Validation / Test Split\nroot_dir = './OralCancer/'              # Dataset Root Folder\nclasses_dir = ['cancer', 'non-cancer']  # Classes\nTrainValTestSplit(root_dir, classes_dir);","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:52:16.328696Z","iopub.execute_input":"2022-06-13T07:52:16.329901Z","iopub.status.idle":"2022-06-13T07:52:16.368585Z","shell.execute_reply.started":"2022-06-13T07:52:16.329842Z","shell.execute_reply":"2022-06-13T07:52:16.367549Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Building Model \n","metadata":{}},{"cell_type":"code","source":"# Importing Keras for Image Classification\nimport keras\nfrom keras.layers import Dense,Conv2D, Flatten, MaxPool2D, Dropout\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:52:27.878093Z","iopub.execute_input":"2022-06-13T07:52:27.879083Z","iopub.status.idle":"2022-06-13T07:52:34.516155Z","shell.execute_reply.started":"2022-06-13T07:52:27.879022Z","shell.execute_reply":"2022-06-13T07:52:34.514992Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# CNN Model \n\nmodel = Sequential() \n\n# Convolutional Layer with input shape (256,256,3)\nmodel.add(Conv2D(filters=32, kernel_size= (3,3), activation= 'relu', input_shape=(256,256,3)) )\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dropout(rate=0.25))\nmodel.add(Dense(units=1, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']  )\n \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:52:38.749869Z","iopub.execute_input":"2022-06-13T07:52:38.750266Z","iopub.status.idle":"2022-06-13T07:52:39.249023Z","shell.execute_reply.started":"2022-06-13T07:52:38.750227Z","shell.execute_reply":"2022-06-13T07:52:39.247923Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Preparing data using data generator ","metadata":{}},{"cell_type":"code","source":"# Expand the size of dataset with new transformed images from the original dataset using ImageDataGenerator.\ntrain_datagen = image.ImageDataGenerator(zoom_range = 0.2, shear_range = 0.2 , rescale = 1./255 , horizontal_flip=True)\nval_datagen = image.ImageDataGenerator(rescale = 1./255)\ntest_datagen = image.ImageDataGenerator(rescale = 1./255)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:01.143792Z","iopub.execute_input":"2022-06-13T07:55:01.144696Z","iopub.status.idle":"2022-06-13T07:55:01.151967Z","shell.execute_reply.started":"2022-06-13T07:55:01.144638Z","shell.execute_reply":"2022-06-13T07:55:01.150625Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data = train_datagen.flow_from_directory(directory= \"./train\", target_size=(256,256), batch_size=32, class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:04.204709Z","iopub.execute_input":"2022-06-13T07:55:04.205134Z","iopub.status.idle":"2022-06-13T07:55:05.084697Z","shell.execute_reply.started":"2022-06-13T07:55:04.205094Z","shell.execute_reply":"2022-06-13T07:55:05.083831Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_data.class_indices","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:11.113339Z","iopub.execute_input":"2022-06-13T07:55:11.113783Z","iopub.status.idle":"2022-06-13T07:55:11.125624Z","shell.execute_reply.started":"2022-06-13T07:55:11.113737Z","shell.execute_reply":"2022-06-13T07:55:11.124167Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"val_data = val_datagen.flow_from_directory(directory= \"./val\", target_size=(256,256), batch_size=32, class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:15.357700Z","iopub.execute_input":"2022-06-13T07:55:15.358606Z","iopub.status.idle":"2022-06-13T07:55:15.468959Z","shell.execute_reply.started":"2022-06-13T07:55:15.358461Z","shell.execute_reply":"2022-06-13T07:55:15.468239Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_data = test_datagen.flow_from_directory(directory= \"./test\", target_size=(256,256), batch_size=32, class_mode = 'binary')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:21.009271Z","iopub.execute_input":"2022-06-13T07:55:21.009869Z","iopub.status.idle":"2022-06-13T07:55:21.120728Z","shell.execute_reply.started":"2022-06-13T07:55:21.009825Z","shell.execute_reply":"2022-06-13T07:55:21.118370Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Adding Model check point Callback\nmc = ModelCheckpoint(filepath=\"oral_cancer_best_model.hdf5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto');\ncall_back = [ mc ];","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:26.790578Z","iopub.execute_input":"2022-06-13T07:55:26.791584Z","iopub.status.idle":"2022-06-13T07:55:26.797693Z","shell.execute_reply.started":"2022-06-13T07:55:26.791530Z","shell.execute_reply":"2022-06-13T07:55:26.796601Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Fitting the Model\ncnn = model.fit(train_data, \n                  steps_per_epoch = 2, \n                  epochs = 32, \n                  validation_data = val_data, \n                  validation_steps = 1,\n                  callbacks = call_back )","metadata":{"execution":{"iopub.status.busy":"2022-06-13T07:55:29.986146Z","iopub.execute_input":"2022-06-13T07:55:29.987305Z","iopub.status.idle":"2022-06-13T08:00:54.521355Z","shell.execute_reply.started":"2022-06-13T07:55:29.987245Z","shell.execute_reply":"2022-06-13T08:00:54.519954Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Loading the Best Fit Model \nmodel = load_model(\"./oral_cancer_best_model.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T08:03:00.350903Z","iopub.execute_input":"2022-06-13T08:03:00.351900Z","iopub.status.idle":"2022-06-13T08:03:00.643137Z","shell.execute_reply.started":"2022-06-13T08:03:00.351842Z","shell.execute_reply":"2022-06-13T08:03:00.641989Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Model Accuracy","metadata":{}},{"cell_type":"code","source":"# Checking the Accuracy of the Model \naccuracy = model.evaluate_generator(generator= test_data)[1] \nprint(f\"The accuracy of the model is = {accuracy*100} %\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T08:03:07.565816Z","iopub.execute_input":"2022-06-13T08:03:07.569687Z","iopub.status.idle":"2022-06-13T08:03:08.369072Z","shell.execute_reply.started":"2022-06-13T08:03:07.569597Z","shell.execute_reply":"2022-06-13T08:03:08.367897Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"h =  cnn.history\nh.keys()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T08:03:22.907616Z","iopub.execute_input":"2022-06-13T08:03:22.908329Z","iopub.status.idle":"2022-06-13T08:03:22.914724Z","shell.execute_reply.started":"2022-06-13T08:03:22.908251Z","shell.execute_reply":"2022-06-13T08:03:22.913676Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Ploting Accuracy In Training Set & Validation Set\nplt.plot(h['accuracy'])\nplt.plot(h['val_accuracy'] , c = \"red\")\nplt.title(\"acc vs v-acc\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T08:03:34.999420Z","iopub.execute_input":"2022-06-13T08:03:35.001038Z","iopub.status.idle":"2022-06-13T08:03:35.434674Z","shell.execute_reply.started":"2022-06-13T08:03:35.000914Z","shell.execute_reply":"2022-06-13T08:03:35.430684Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Ploting Loss In Training Set & Validation Set\nplt.plot(h['loss'])\nplt.plot(h['val_loss'] , c = \"red\")\nplt.title(\"loss vs v-loss\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T08:03:45.946270Z","iopub.execute_input":"2022-06-13T08:03:45.946680Z","iopub.status.idle":"2022-06-13T08:03:46.192402Z","shell.execute_reply.started":"2022-06-13T08:03:45.946636Z","shell.execute_reply":"2022-06-13T08:03:46.190514Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def cancerPrediction(path):\n    # Loading Image\n    img = image.load_img(path, target_size=(256,256))\n    # Normalizing Image\n    norm_img = image.img_to_array(img)/255\n    # Converting Image to Numpy Array\n    input_arr_img = np.array([norm_img])\n    # Getting Predictions\n    pred = (model.predict(input_arr_img) > 0.5).astype(int)[0][0]\n    # Printing Model Prediction\n    if pred == 0:\n        print(\"Cancer\")\n    else:\n        print(\"Non-Cancer\")\n    \n# Path for the image to get predictions    \npath = \"../input/oral-cancer-lips-and-tongue-images/OralCancer/cancer/01960a64-cfe8-444d-bbc5-575c15389a21.jpg\"\ncancerPrediction(path)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T08:04:06.330200Z","iopub.execute_input":"2022-06-13T08:04:06.330619Z","iopub.status.idle":"2022-06-13T08:04:06.646561Z","shell.execute_reply.started":"2022-06-13T08:04:06.330577Z","shell.execute_reply":"2022-06-13T08:04:06.645288Z"},"trusted":true},"execution_count":21,"outputs":[]}]}